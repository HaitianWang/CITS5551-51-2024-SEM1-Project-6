{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load from files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 16:28:25.887516: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-23 16:28:27.068021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, concatenate, Input, BatchNormalization, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import rasterio\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = './testb'\n",
    "pattern = re.compile(r'smalldata_(\\d+)_(\\d+)')\n",
    "indices = ['ExG', 'ExR', 'PRI', 'MGRVI', 'SAVI', 'MSAVI', 'EVI', 'REIP', 'NDVI', 'GNDVI', 'CI', 'OSAVI', 'TVI', 'MCARI', 'TCARI']\n",
    "\n",
    "def load_tif(file_path):\n",
    "    # Function to load .tif file and return as a numpy array using rasterio\n",
    "    with rasterio.open(file_path) as src:\n",
    "        return src.read(1)  # Read the first band\n",
    "\n",
    "def read_X(dir=base_path, indices=indices):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for dir_name in dirs:\n",
    "            match = pattern.match(dir_name)\n",
    "            if match:\n",
    "                group_number = match.group(1)\n",
    "                sub_group_number = match.group(2)\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                channels = []\n",
    "                skip_directory = False\n",
    "                for file_name in os.listdir(dir_path):\n",
    "                    if file_name.endswith('.tif'):\n",
    "                        for index in indices:\n",
    "                            if file_name.startswith(index):\n",
    "                                file_path = os.path.join(dir_path, file_name)\n",
    "                                data = load_tif(file_path)\n",
    "                                if np.isnan(data).any():\n",
    "                                    print(f\"Skipping directory due to NaN values in: {file_path}\")\n",
    "                                    skip_directory = True\n",
    "                                    break\n",
    "                                channels.append(data)\n",
    "                        if skip_directory:\n",
    "                            break\n",
    "                    if file_name.startswith(\"label_matrix\"):\n",
    "                        file_path = os.path.join(dir_path, file_name)\n",
    "                        label_matrix = pd.read_csv(file_path, header=None).values\n",
    "                if not skip_directory:\n",
    "                    images.append(channels)\n",
    "                    labels.append(label_matrix)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# # Example usage\n",
    "# images, labels = read_X()\n",
    "# print(images.shape, labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping directory due to NaN values in: ./testb/smalldata_26_26/NDVI_26_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_28/ExG_1_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_24/TCARI_25_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_12_27/ExR_12_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_15/MCARI_1_15.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_28/TCARI_27_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_23/TVI_1_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_26/TVI_13_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_5/ExG_1_5.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_29/SAVI_24_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_27/ExR_1_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_21/CI_1_21.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_12_28/ExG_12_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_7_1/MCARI_7_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_23/REIP_22_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_20/MSAVI_1_20.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_25/GNDVI_26_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_1/EVI_11_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_19/REIP_1_19.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_27/PRI_15_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_16/GNDVI_1_16.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_26/ExR_1_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_28/EVI_23_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_29/CI_1_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_6/OSAVI_27_6.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_22/TCARI_1_22.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_2_28/GNDVI_2_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_27/EVI_14_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_25/ExG_27_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_9/TCARI_27_9.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_23/TVI_25_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_27/TCARI_9_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_26/GNDVI_9_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_14/PRI_1_14.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_12_1/REIP_12_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_29/SAVI_10_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_2/ExG_10_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_1/EVI_9_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_26/ExG_21_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_1/TCARI_15_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_4_29/MCARI_4_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_24/MSAVI_24_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_29/GNDVI_15_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_9/REIP_1_9.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_25/MGRVI_24_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_20/PRI_27_20.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_7/MGRVI_27_7.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_27/NDVI_25_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_11/NDVI_1_11.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_1/TCARI_10_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_7_28/SAVI_7_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_2/MGRVI_14_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_2/ExG_27_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_26/ExR_8_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_26/NDVI_15_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_28/TCARI_22_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_26/ExG_27_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_25/EVI_1_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_6_1/MGRVI_6_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_29/EVI_21_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_6/SAVI_1_6.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_28/TCARI_9_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_12/TCARI_27_12.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_29/EVI_22_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_24/MGRVI_21_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_24/NDVI_23_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_26/TVI_14_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_27/ExG_24_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_1/ExG_1_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_8/NDVI_1_8.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_27/MGRVI_11_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_28/TVI_13_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_11/TVI_27_11.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_14/MSAVI_27_14.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_12_29/PRI_12_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_12/GNDVI_1_12.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_29/PRI_25_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_27/GNDVI_8_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_2/ExG_26_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_27/MSAVI_27_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_3_29/NDVI_3_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_3_2/CI_3_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_25/OSAVI_22_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_6_29/EVI_6_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_23/PRI_21_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_2_4/MCARI_2_4.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_1/ExR_27_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_19/OSAVI_27_19.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_17/TCARI_27_17.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_29/GNDVI_26_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_4/PRI_27_4.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_28/REIP_24_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_3/OSAVI_1_3.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_28/MCARI_11_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_2/MGRVI_1_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_7_2/CI_7_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_3/MGRVI_27_3.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_18/SAVI_1_18.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_2/GNDVI_8_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_26/TCARI_23_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_1/NDVI_26_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_5_29/TCARI_5_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_25/OSAVI_14_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_29/TVI_23_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_29/SAVI_8_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_27/ExG_23_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_2_2/ExG_2_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_17/REIP_1_17.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_26/MSAVI_24_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_1/ExR_21_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_24/TCARI_26_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_29/MGRVI_11_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_5/NDVI_27_5.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_27/REIP_26_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_1/MCARI_14_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_4/GNDVI_1_4.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_1/TCARI_23_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_25/PRI_25_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_28/ExR_15_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_28/TCARI_10_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_28/NDVI_8_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_2/OSAVI_9_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_2/PRI_13_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_28/REIP_25_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_27/GNDVI_22_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_6_2/CI_6_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_26/TCARI_22_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_8/EVI_27_8.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_27/OSAVI_21_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_4_2/MGRVI_4_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_1/MGRVI_13_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_1/TVI_24_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_25/GNDVI_21_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_13/MGRVI_27_13.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_24_23/TCARI_24_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_28/SAVI_14_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_10/NDVI_27_10.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_23/MCARI_26_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_7/PRI_1_7.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_5_2/SAVI_5_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_26/PRI_10_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_22/TCARI_27_22.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_12_26/MGRVI_12_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_24/MSAVI_15_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_1/MSAVI_25_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_26_28/MSAVI_26_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_24/MSAVI_1_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_21_28/MGRVI_21_28.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_25_26/GNDVI_25_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_27/TVI_13_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_3_1/ExR_3_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_25/TCARI_23_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_7_29/CI_7_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_10_27/EVI_10_27.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_2_1/TCARI_2_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_9_29/ExG_9_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_13_29/NDVI_13_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_2/EVI_11_2.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_4_1/MCARI_4_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_29/ExR_27_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_16/TVI_27_16.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_1/REIP_22_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_2_29/GNDVI_2_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_23/CI_27_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_13/ExR_1_13.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_23_23/ExG_23_23.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_14_29/MSAVI_14_29.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_15_25/REIP_15_25.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_27_24/MGRVI_27_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_11_26/MSAVI_11_26.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_8_1/OSAVI_8_1.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_22_24/REIP_22_24.tif\n",
      "Skipping directory due to NaN values in: ./testb/smalldata_1_10/SAVI_1_10.tif\n"
     ]
    }
   ],
   "source": [
    "X,y=read_X()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_to_one_hot(y):\n",
    "    # Get the shape of the input array\n",
    "    n, h, w = y.shape\n",
    "    \n",
    "    # Initialize an all-zero array with shape (n, h, w, 4)\n",
    "    y_one_hot = np.zeros((n, h, w, 4), dtype=int)\n",
    "    \n",
    "    # Use advanced indexing to convert the original array values to one-hot encoding\n",
    "    for i in range(4):\n",
    "        y_one_hot[..., i] = (y == i)\n",
    "    \n",
    "    return y_one_hot\n",
    "\n",
    "\n",
    "def get_predicted_labels(predictions):\n",
    "    \"\"\"\n",
    "    Convert the predicted probability array to a label array.\n",
    "    \n",
    "    Parameters:\n",
    "    predictions: A predicted probability array with shape (n, 512, 512, 4)\n",
    "    \n",
    "    Returns:\n",
    "    A label array with shape (n, 512, 512), where each point represents its most probable class\n",
    "    \"\"\"\n",
    "    predicted_labels = np.argmax(predictions, axis=-1)\n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "def one_hot_to_labels(y_one_hot):\n",
    "    \"\"\"\n",
    "    Convert a one-hot encoded array back to a label array.\n",
    "    \n",
    "    Parameters:\n",
    "    y_one_hot: A one-hot encoded array with shape (n, 512, 512, 4)\n",
    "    \n",
    "    Returns:\n",
    "    A label array with shape (n, 512, 512)\n",
    "    \"\"\"\n",
    "    # Use np.argmax to find the index of the maximum value in the fourth dimension\n",
    "    y_labels = np.argmax(y_one_hot, axis=-1)\n",
    "    \n",
    "    return y_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input data to [0, 1]\n",
    "X = X / np.max(X)\n",
    "\n",
    "# Transpose the dimensions of X to (0, 2, 3, 1)\n",
    "X = X.transpose((0, 2, 3, 1))\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y_one_hot = convert_to_one_hot(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_image(image, label):\n",
    "    # Do not resize, keep the original dimensions\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(images, labels, batch_size=4):\n",
    "    # Create a TensorFlow dataset from the images and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    \n",
    "    # Apply the preprocess_image function to each element in the dataset\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    # Batch the dataset and prefetch for better performance\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Load the training dataset\n",
    "train_dataset = load_dataset(X, y_one_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 512, 3)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 512)\n",
      "(None, 14, 14, 4)\n",
      "(None, 512, 512, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a custom ResizeLayer\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_height, target_width):\n",
    "        super(ResizeLayer, self).__init__()\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, (self.target_height, self.target_width))\n",
    "\n",
    "# Define the input tensor with shape (512, 512, 15)\n",
    "input_tensor = Input(shape=(512, 512, 15))\n",
    "\n",
    "# Add a convolutional layer to convert the input to a 3-channel input suitable for InceptionV3\n",
    "x = Conv2D(3, (1, 1), padding='same', activation='relu')(input_tensor)\n",
    "print(x.shape)  # 512\n",
    "\n",
    "# Use the pre-trained InceptionV3 model, excluding the top classification layer\n",
    "base_model = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(512, 512, 3))\n",
    "\n",
    "# Connect the custom input layer to the base model\n",
    "x = base_model(x)\n",
    "\n",
    "# Use convolutional layers to maintain the spatial dimensions\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Add the final convolutional layer\n",
    "x = Conv2D(4, (1, 1), padding='same')(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Use the custom resize layer to resize the output to (512, 512)\n",
    "x = ResizeLayer(512, 512)(x)\n",
    "print(x.shape)\n",
    "\n",
    "# Apply the Softmax activation function to ensure the output represents a probability distribution\n",
    "predictions = tf.keras.layers.Softmax(axis=-1)(x)\n",
    "\n",
    "# Define the model with the input tensor and the predictions\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "# Freeze the convolutional layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with RMSprop optimizer and categorical cross-entropy loss\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Uncomment the lines below to print the predictions shape and verify the sum of probabilities\n",
    "# print(predictions.shape)\n",
    "# print(predictions)\n",
    "# print(np.sum(predictions[0, :, :, :], axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 1s/step - accuracy: 0.7982 - loss: 2.5025\n",
      "Epoch 2/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5469\n",
      "Epoch 3/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5279\n",
      "Epoch 4/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5232\n",
      "Epoch 5/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5203\n",
      "Epoch 6/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5165\n",
      "Epoch 7/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5142\n",
      "Epoch 8/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5119\n",
      "Epoch 9/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5111\n",
      "Epoch 10/10\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.8644 - loss: 0.5081\n"
     ]
    }
   ],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_loss') <= 0.1099 and logs.get('loss') <= 0.1099:\n",
    "            print('\\n\\n Reached The Destination!')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10\n",
    "    # callbacks=[callbacks]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as inceptionv3_fcn_model_23_5.h5\n"
     ]
    }
   ],
   "source": [
    "model_path='./inceptionv3_fcn_model_23_5.h5'\n",
    "\n",
    "model.save(model_path)\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at ./inceptionv3_fcn_model_23_5.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Model saved successfully at {model_path}\")\n",
    "else:\n",
    "    print(f\"Model not found at {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-23 16:30:14.185432: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define custom layer without 'trainable' argument\n",
    "class ResizeLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, target_height, target_width, **kwargs):\n",
    "        super(ResizeLayer, self).__init__(**kwargs)\n",
    "        self.target_height = target_height\n",
    "        self.target_width = target_width\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, [self.target_height, self.target_width])\n",
    "\n",
    "# Add custom layer to the custom_objects dictionary\n",
    "custom_objects = {'ResizeLayer': ResizeLayer}\n",
    "\n",
    "# Load the model with the custom objects\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    model = load_model('inceptionv3_fcn_model_23_5.h5', compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(dir):\n",
    "    # Read the test data from the specified directory\n",
    "    X_test, y_test = read_X(dir=dir)\n",
    "    \n",
    "    # Print the shape and data type of the test data\n",
    "    print(f\"Shape of X_test: {X_test.shape}\")\n",
    "    print(f\"Data type of X_test: {X_test.dtype}\")\n",
    "    \n",
    "    # Normalize the test data to the range [0, 1]\n",
    "    X_test = X_test / np.max(X_test)\n",
    "    \n",
    "    # Transpose the dimensions of X_test to (0, 2, 3, 1)\n",
    "    X_test = X_test.transpose((0, 2, 3, 1))\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Uncomment the following line to print the predictions\n",
    "    # print(predictions)\n",
    "    \n",
    "    # Convert y_test to one-hot encoding\n",
    "    y_test_one_hot = convert_to_one_hot(y_test)\n",
    "    \n",
    "    return y_test_one_hot, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test: (2, 15, 512, 512)\n",
      "Data type of X_test: float32\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test,y_pred= make_pred(dir='./testset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all sums of the four channels equal to 1? True\n"
     ]
    }
   ],
   "source": [
    "# Check if the sum of channel values for each pixel is equal to 1\n",
    "sum_of_channels = np.sum(y_pred, axis=-1)\n",
    "#print(sum_of_channels)\n",
    "\n",
    "# Verify if all values are close to 1\n",
    "are_all_close_to_one = np.allclose(sum_of_channels, 1)\n",
    "print(f\"Are all sums of the four channels equal to 1? {are_all_close_to_one}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7980842590332031"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(y_true, y_pred, num_classes=4):\n",
    "    \"\"\"\n",
    "    Calculate classification accuracy.\n",
    "    \n",
    "    :param y_true: Actual labels, shape (batch_size, height, width, num_classes)\n",
    "    :param y_pred: Predicted labels, shape (batch_size, height, width, num_classes)\n",
    "    :param num_classes: Number of classes\n",
    "    :return: Classification accuracy\n",
    "    \"\"\"\n",
    "    # Convert one-hot encoded labels to class indices\n",
    "    y_true_class = np.argmax(y_true, axis=-1)\n",
    "    y_pred_class = np.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    correct_predictions = np.sum(y_true_class == y_pred_class)\n",
    "    total_predictions = y_true_class.size\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Call the function to calculate accuracy\n",
    "calculate_accuracy(y_test, y_pred, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4495210647583008"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_miou(y_true, y_pred, num_classes):\n",
    "    \"\"\"\n",
    "    Calculate Mean Intersection over Union (mIoU).\n",
    "    \n",
    "    :param y_true: Actual labels, shape (batch_size, height, width, num_classes)\n",
    "    :param y_pred: Predicted labels, shape (batch_size, height, width, num_classes)\n",
    "    :param num_classes: Number of classes\n",
    "    :return: Mean Intersection over Union (mIoU)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert one-hot encoded labels to class indices\n",
    "    y_true = np.argmax(y_true, axis=-1)\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    iou_list = []\n",
    "    for c in range(num_classes):\n",
    "\n",
    "        \n",
    "        # Create boolean arrays for the current class\n",
    "        true_class = (y_true == c)\n",
    "        pred_class = (y_pred == c)\n",
    "        \n",
    "        # Calculate the intersection and union for the current class\n",
    "        intersection = np.sum(true_class & pred_class)\n",
    "        \n",
    "        union = np.sum(true_class | pred_class)\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = 1.0  # If there is no ground truth or predicted instance in this class\n",
    "\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "\n",
    "        \n",
    "        # Append the IoU for the current class to the list\n",
    "        iou_list.append(iou)\n",
    "    \n",
    "    # Calculate the mean IoU across all classes\n",
    "    miou = np.mean(iou_list)\n",
    "    \n",
    "    return miou\n",
    "\n",
    "# Call the function to calculate mIoU\n",
    "calculate_miou(y_test, y_pred, num_classes=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
